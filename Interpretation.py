# -*- coding: utf-8 -*-
"""Hybrid_Model_With_GradCam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Df9eVhZeT6KwNCRS3zqpC70ZFg8EQk6
"""

# Segment 1: Setup, constants, model loading, and image preprocessing
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image as kimage

# CONFIG â€” update these paths / names before running
IMAGE_SIZE = (224, 224)
MODEL_PATH = '/content/drive/MyDrive/models/Cauli_Net.h5'
LAST_CONV_LAYER_NAME = 'conv2d_27'
CLASS_NAMES = ['Bacterial Spot', 'Black Rot', 'Downy Mildew', 'Healthy']

# Load trained model (no try/except; ensure MODEL_PATH is correct)
model = tf.keras.models.load_model(MODEL_PATH)
print("Model loaded. Verify last conv layer name with: [l.name for l in model.layers][-20: ]")

# Preprocessing helper
def load_and_preprocess_image(img_path, image_size=IMAGE_SIZE):
    """Load image, resize, convert to float32 and scale to [0,1]. Returns batch of shape (1,h,w,3)."""
    img = kimage.load_img(img_path, target_size=image_size)
    arr = kimage.img_to_array(img).astype(np.float32) / 255.0
    return np.expand_dims(arr, axis=0)

#Example:
img_batch = load_and_preprocess_image('/content/drive/MyDrive/Augmented_Dataset/split/val/Class_A/image_01.jpg')
print(img_batch.shape)

# Segment 2: Grad-CAM utilities and visualization
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

def make_gradcam_heatmap(img_batch, model, last_conv_layer_name, pred_index=None):
    """
    img_batch: shape (1,h,w,3) with values in [0,1]
    returns: heatmap as 2D numpy array normalized 0..1
    """
    grad_model = tf.keras.models.Model([model.inputs],
                                       [model.get_layer(last_conv_layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_batch)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        loss = predictions[:, pred_index]

    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = tf.tensordot(conv_outputs, pooled_grads, axes=([2], [0]))
    heatmap = tf.maximum(heatmap, 0)
    max_val = tf.reduce_max(heatmap)
    heatmap = heatmap / (max_val + tf.keras.backend.epsilon())
    return heatmap.numpy()

def overlay_heatmap_on_image(img_path, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET, image_size=IMAGE_SIZE):
    orig = cv2.imread(img_path)
    orig = cv2.resize(orig, image_size)
    heatmap_uint8 = np.uint8(255 * heatmap)
    heatmap_color = cv2.applyColorMap(heatmap_uint8, colormap)
    overlay = cv2.addWeighted(heatmap_color, alpha, orig, 1 - alpha, 0)
    # Convert BGR->RGB for matplotlib
    return cv2.cvtColor(orig, cv2.COLOR_BGR2RGB), cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB), heatmap_color

def show_gradcam(img_path, model, last_conv_layer_name, class_names=CLASS_NAMES):
    img_batch = load_and_preprocess_image(img_path)
    preds = model.predict(img_batch)[0]
    pred_index = int(np.argmax(preds))
    pred_class = class_names[pred_index]

    heatmap = make_gradcam_heatmap(img_batch, model, last_conv_layer_name, pred_index)
    orig_rgb, overlay_rgb, heatmap_color = overlay_heatmap_on_image(img_path, heatmap)

    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1); plt.imshow(orig_rgb); plt.title("Original"); plt.axis('off')
    plt.subplot(1,3,2); plt.imshow(heatmap, cmap='jet'); plt.title("Heatmap (0..1)"); plt.axis('off')
    plt.subplot(1,3,3); plt.imshow(overlay_rgb); plt.title(f"Overlay -> {pred_class}"); plt.axis('off')
    plt.show()

# Example:
show_gradcam('/content/drive/MyDrive/Augmented_Dataset/split/val/Class_A/image_01.jpg', model, LAST_CONV_LAYER_NAME)

# Segment 3: LIME explanations for single image
import numpy as np
from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

def predict_for_lime(images_batch):
    """
    LIME gives images as uint8 arrays (0..255). Convert to [0,1] float batch that matches model input.
    Return model predictions (N, num_classes).
    """
    imgs = np.array(images_batch).astype(np.float32) / 255.0
    return model.predict(imgs)

def explain_with_lime(img_path, model, class_names=CLASS_NAMES, num_samples=500, num_features=5):
    # load image as uint8 array for LIME
    from tensorflow.keras.preprocessing.image import load_img, img_to_array
    img = load_img(img_path, target_size=IMAGE_SIZE)
    img_arr = img_to_array(img).astype(np.uint8)

    explainer = lime_image.LimeImageExplainer()
    explanation = explainer.explain_instance(
        img_arr,
        classifier_fn=predict_for_lime,
        top_labels=1,
        hide_color=0,
        num_samples=num_samples
    )

    top_label = explanation.top_labels[0]
    temp, mask = explanation.get_image_and_mask(
        top_label,
        positive_only=True,
        num_features=num_features,
        hide_rest=True
    )

    plt.figure(figsize=(8,8))
    plt.imshow(mark_boundaries(temp / 255.0, mask))
    plt.title(f"LIME explanation for class: {class_names[top_label]}")
    plt.axis('off')
    plt.show()

# Example:
explain_with_lime('/content/drive/MyDrive/Augmented_Dataset/split/val/Class_A/image_01.jpg', model)

#Training data TNSE

import numpy as np
from sklearn.manifold import TSNE

# Load the trained model
model = Model_PATH

# Create a new model without the final dense layer
feature_extractor_model = Model(inputs=model.input, outputs=model.get_layer('global_average_pooling2d').output)

# Get the intermediate features for the validation data
X_train_features = feature_extractor_model.predict([X_train,X_train])

# Apply t-SNE on the features
tsne = TSNE(n_components=3, random_state=42)
X_train_tsne = tsne.fit_transform(X_train_features)

# X_val_tsne now contains the t-SNE embeddings for the validation data

import numpy as np
import matplotlib.pyplot as plt

# Convert one-hot encoded labels to class indices
Y_val_indices = np.argmax(Y_val, axis=1)

# Plot the t-SNE embeddings with colored labels
plt.figure(figsize=(10, 8))
plt.scatter(X_val_tsne[:, 0], X_val_tsne[:, 1], c=Y_val_indices, cmap='viridis')
plt.colorbar()
plt.title('t-SNE Visualization of Validation Data')
plt.xlabel('t-SNE Dimension 1')
plt.ylabel('t-SNE Dimension 2')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Convert one-hot encoded labels to class indices
#y_val_indices = np.argmax(y_val, axis=1)

# Create a 3D scatter plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_val_tsne[:, 0], X_val_tsne[:, 1], X_val_tsne[:, 2], c=Y_val_indices, cmap='viridis')
ax.set_title('t-SNE Visualization of Validation Data (3D)')
ax.set_xlabel('t-SNE Dimension 1')
ax.set_ylabel('t-SNE Dimension 2')
ax.set_zlabel('t-SNE Dimension 3')
fig.colorbar(scatter)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Convert one-hot encoded labels to class indices
Y_train_indices = np.argmax(Y_train, axis=1)

# Create a 3D scatter plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], X_train_tsne[:, 2], c=Y_train_indices, cmap='viridis')
ax.set_title('t-SNE Visualization of Training Data (3D)')
ax.set_xlabel('t-SNE Dimension 1')
ax.set_ylabel('t-SNE Dimension 2')
ax.set_zlabel('t-SNE Dimension 3')
fig.colorbar(scatter)
plt.show()