# -*- coding: utf-8 -*-
"""Hybrid_Model_With_GradCam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aDvRjK0hMLnwVAeCy28UGTlQIkkyGORx
"""

import tensorflow.keras.backend as K
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.applications import VGG16, MobileNetV2
from tensorflow.keras.models import Model
import tensorflow as tf

# Define the Mrelu activation function

def mrelu(x):
    return K.pow(K.maximum(0.0, x), 1.0000001)

def fru_model(input_shape = (224, 224, 3)):
    # Input layer
    inputs1 = Input(shape=input_shape)
    # Block 1
    x = Conv2D(64, (3, 3), padding='same')(inputs1)
    x = Activation(mrelu)(x)
    x = Conv2D(64, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
    # Block 2
    x = Conv2D(128, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(128, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
    # Block 3
    x = Conv2D(256, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(256, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(256, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
    # Block 4
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
    # Block 5
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = Activation(mrelu)(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)

     # Create the first model
    model1 = Model(inputs=inputs1, outputs=x, name='FruModel')

    # Create the second model (MobileNetV2)
    base_model1 = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
                                               include_top=False,
                                               weights='imagenet')
    base_model1.trainable = False
    X_input = Input(shape = (224, 224, 3))
    X = base_model1(X_input)
    model2 = Model(inputs = X_input, outputs = X, name = 'MobileNetV2')


    # Concatenate the outputs of both models
    combined = concatenate([model1.output, model2.output])

    # Add a dilution layer before global average pooling
    dilution_output = Conv2D(filters=1792, kernel_size=(1, 1), activation='relu')(combined)

    # Apply global average pooling to reduce the spatial dimensions of the dilution output
    pooled_output = GlobalAveragePooling2D()(dilution_output)

    # Set the number of classes
    num_classes = 4

    # Add a dense layer for classification
    predictions = Dense(num_classes, activation='softmax')(pooled_output)

    # Create the final model
    model = Model(inputs=[model1.input, model2.input], outputs=predictions, name='CombinedModel')

    # Compile the model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model=fru_model()
model.summary()

from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
from keras.callbacks import LearningRateScheduler
import math
def decay(epoch, steps=100):
    initial_lrate = 0.001
    drop = 0.96
    epochs_drop = 8
    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))
    return lrate

lr_sc = LearningRateScheduler(decay, verbose=1)

# early stopping
callbacks = EarlyStopping(patience = 4, monitor='val_loss')

tf.keras.utils.plot_model(
    model,
    to_file='model.png',
    show_shapes=True,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=400,
    layer_range=None,
    show_layer_activations=False,
    show_trainable=False
)

model.summary()

